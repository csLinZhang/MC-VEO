
<head>
<meta http-equiv="Content-Language" content="zh-cn">
<meta http-equiv="Content-Type" content="text/html; charset=gb2312">
<title>MC-VEO</title>

<style>
<!--
div.Section1
	{page:Section1;}
 table.MsoNormalTable
	{mso-style-parent:"";
	font-size:10.0pt;
	font-family:"Times New Roman","serif"}
table.TableGrid
	{border:1.0pt solid black;
	font-size:10.0pt;
	font-family:"Times New Roman";
	}
-->
</style>
<meta http-equiv="Content-Language" content="zh-cn">
<meta http-equiv="Content-Type" content="text/html; charset=gb2312">
<title>MC-VEO</title>

<style>
<!--
div.Section1
	{page:Section1;}
 table.MsoNormalTable
	{mso-style-parent:"";
	font-size:10.0pt;
	font-family:"Times New Roman","serif"}
table.TableGrid
	{border:1.0pt solid black;
	font-size:10.0pt;
	font-family:"Times New Roman";
	}
-->
</style>
</head>

<html xmlns:v="urn:schemas-microsoft-com:vml" xmlns:o="urn:schemas-microsoft-com:office:office" xmlns="http://www.w3.org/TR/REC-html40">

<body>

<table class="MsoNormalTable" border="0" cellpadding="0" width="1217" id="table3" height="35">
	<tr>
		<td valign="top" style="width: 1211px; height: 31px; padding: .75pt" align="left">
		<p class="text">
		<span lang="en-us"><font face="Calibri" size="5" color="#0000FF">
		<b> MC-VEO: A Visual-Event Odometry with Accurate 6-DoF Motion Compensation</b></font></span><p class="text">
		<span lang="en-us"><font face="Calibri" size="4" color="#0000FF">
		Jiafeng Huang<sup>1</sup>,&nbsp;
		Lin Zhang<sup>1</sup>,&nbsp;
		Tianjun Zhang<sup>1</sup>,&nbsp;
		and Shengjie Zhao<sup>1</sup>
		<p>
		<sup>1</sup>School of Software Engineering, Tongji University, Shanghai, China
		<p>
	</tr>
	</table>
<hr>
<p><span lang="en-us"><b><font face="Calibri" size="5">Introduction</font></b></span></p>
<p>
<span style="font-size: 13pt; font-family: Calibri; color: windowtext" lang="EN-US">
This is the website for our paper MC-VEO: A Visual-Event Odometry with Accurate 6-DoF Motion Compensation.

<p>
Nowadays, robust and accurate odometries, as the foundation technology of navigation systems, gains significance in autonomous driving and robotic navigation fields.
Although odometries, especially visual odometries (VOs), have made substantial progress, their application scenarios are still limited by the normal cameras’ frame rate limitations and their low robustness to motion blur.
The event camera, a recently proposed bionic sensor, seeks to tackle these challenges, offering new possibilities for VO solutions to overcome extreme environments.
However, integrating event cameras into VO faces challenges like the RGB-event modality gap and the requirement for efficient event processing.
To address these research gaps to some extent, we propose a novel visual-event odometry, namely MC-VEO (Motion Compensated Visual-Event Odometry).

<hr>
<p><span lang="en-us"><b><font face="Calibri" size="5">Overall Framwork</font></b></span></p>
<p>
<span lang="en-us"><font face="Calibri" style="font-size: 13pt">The overall pipeline of our proposed MC-VEO is shown in the following figure.
The events obtained from the event camera are divided into groups, and after motion compensation, clear event frames are formed.
The images obtained from the color camera go through keyframe judgment and candidate point selection to predict and form the brightness increments.
The event generative model is used to correlate measurements from events and images.
The front-end predicts camera motion by minimizing the brightness increment error of both two kinds of measurements.
The camera pose and velocities as well as the depth of sparse candidate points are refined by photometric bundle adjustment at the back-end to sustain the VO system’s good performance.</font></span></p>
<div style="text-align:center;"><img src="MC-VEO.png" style="zoom: 70%;" /></div>
<div style="text-align:center;"><text style="color:#C0C0C0;text-decoration:underline">Figure 1. The overall pipeline of the MC-VEO.</text></div>
	
<hr>
<p><span lang="en-us"><b><font face="Calibri" size="5">Performances</font></b></span></p>
<p>
<p><span lang="en-us"><b><font face="Calibri" size="4">- Qualitative Results</font></b></span></p>
<div style="text-align:center;"><img src="depth.png" style="zoom: 70%;" /></div>
<div style="text-align:center;"><text style="color:#C0C0C0;text-decoration:underline">Figure 2. Qualitative comparison on four test sequences.
Each row depicts the pseudo-colored inverse depth maps generated by corresponding methods (red represents near and blue for far).
It is worth mentioning that since the timestamps of event frames formed by different methods are not completely aligned, we chose to show results with relatively close perspectives.</text></div>
<p>	
<p><span lang="en-us"><b><font face="Calibri" size="4">- Quantitative Results</font></b></span></p>
<p>
<div style="text-align:center;"><text style="color:#C0C0C0;text-decoration:underline">Table 1. Absolute Translation Errors (cm) of MC-VEO and compared VOs.</text></div>
<p>
<div style="text-align:center;"><img src="ATE.png" style="zoom: 70%;" /></div>
<p>
<div style="text-align:center;"><text style="color:#C0C0C0;text-decoration:underline">Table 2. Rotation Errors (deg) of MC-VEO and compared VOs.</text></div>
<p>
<div style="text-align:center;"><img src="RE.png" style="zoom: 70%;" /></div>
<p>
<span lang="en-us"><font face="Calibri" style="font-size: 13pt">Considering all metrics comprehensively, the performence of the MC-VEO is the best among all compared schemes.	
<hr>
<p><span lang="en-us"><b><font face="Calibri" size="5">Source Codes</font></b></span></p>
<p>
<span lang="en-us"><font face="Calibri" style="font-size: 13pt"> 
<a href="https://github.com/huangfeng95/mc-veo-buildconf">MC-VEO Code</a></font></span></p>
<p>
<hr>
<p><span lang="en-us"><b><font face="Calibri" size="5">Demo Videos</font></b></span></p>
<p>
<span lang="en-us"><font face="Calibri" style="font-size: 13pt">The following is the demo video demonstrating the performance of our MC-VEO in some typical sequences.</font></span></p>
<div style="text-align:center;"><video src="demo.mp4"  height="600"controls preload></video></div>
<hr>
</body>
</html>
